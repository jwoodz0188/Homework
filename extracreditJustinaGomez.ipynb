{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPKHz1TMYWte6EkvRVeBCWd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwoodz0188/Homework/blob/main/extracreditJustinaGomez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import PIL.Image\n",
        "import dlib\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "\n",
        "try:\n",
        "    import face_recognition_models\n",
        "except Exception:\n",
        "    print(\"Please install `face_recognition_models` with this command before using `face_recognition`:\\n\")\n",
        "    print(\"pip install git+https://github.com/ageitgey/face_recognition_models\")\n",
        "    quit()\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "predictor_68_point_model = face_recognition_models.pose_predictor_model_location()\n",
        "pose_predictor_68_point = dlib.shape_predictor(predictor_68_point_model)\n",
        "\n",
        "predictor_5_point_model = face_recognition_models.pose_predictor_five_point_model_location()\n",
        "pose_predictor_5_point = dlib.shape_predictor(predictor_5_point_model)\n",
        "\n",
        "cnn_face_detection_model = face_recognition_models.cnn_face_detector_model_location()\n",
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(cnn_face_detection_model)\n",
        "\n",
        "face_recognition_model = face_recognition_models.face_recognition_model_location()\n",
        "face_encoder = dlib.face_recognition_model_v1(face_recognition_model)\n",
        "\n",
        "\n",
        "def _rect_to_css(rect):\n",
        "    \"\"\"\n",
        "    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\n",
        "\n",
        "    :param rect: a dlib 'rect' object\n",
        "    :return: a plain tuple representation of the rect in (top, right, bottom, left) order\n",
        "    \"\"\"\n",
        "    return rect.top(), rect.right(), rect.bottom(), rect.left()\n",
        "\n",
        "\n",
        "def _css_to_rect(css):\n",
        "    \"\"\"\n",
        "    Convert a tuple in (top, right, bottom, left) order to a dlib `rect` object\n",
        "\n",
        "    :param css:  plain tuple representation of the rect in (top, right, bottom, left) order\n",
        "    :return: a dlib `rect` object\n",
        "    \"\"\"\n",
        "    return dlib.rectangle(css[3], css[0], css[1], css[2])\n",
        "\n",
        "\n",
        "def _trim_css_to_bounds(css, image_shape):\n",
        "    \"\"\"\n",
        "    Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\n",
        "\n",
        "    :param css:  plain tuple representation of the rect in (top, right, bottom, left) order\n",
        "    :param image_shape: numpy shape of the image array\n",
        "    :return: a trimmed plain tuple representation of the rect in (top, right, bottom, left) order\n",
        "    \"\"\"\n",
        "    return max(css[0], 0), min(css[1], image_shape[1]), min(css[2], image_shape[0]), max(css[3], 0)\n",
        "\n",
        "\n",
        "def face_distance(face_encodings, face_to_compare):\n",
        "    \"\"\"\n",
        "    Given a list of face encodings, compare them to a known face encoding and get a euclidean distance\n",
        "    for each comparison face. The distance tells you how similar the faces are.\n",
        "\n",
        "    :param face_encodings: List of face encodings to compare\n",
        "    :param face_to_compare: A face encoding to compare against\n",
        "    :return: A numpy ndarray with the distance for each face in the same order as the 'faces' array\n",
        "    \"\"\"\n",
        "    if len(face_encodings) == 0:\n",
        "        return np.empty((0))\n",
        "\n",
        "    return np.linalg.norm(face_encodings - face_to_compare, axis=1)\n",
        "\n",
        "\n",
        "def load_image_file(file, mode='RGB'):\n",
        "    \"\"\"\n",
        "    Loads an image file (.jpg, .png, etc) into a numpy array\n",
        "\n",
        "    :param file: image file name or file object to load\n",
        "    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\n",
        "    :return: image contents as numpy array\n",
        "    \"\"\"\n",
        "    im = PIL.Image.open(file)\n",
        "    if mode:\n",
        "        im = im.convert(mode)\n",
        "    return np.array(im)\n",
        "\n",
        "\n",
        "def _raw_face_locations(img, number_of_times_to_upsample=1, model=\"hog\"):\n",
        "    \"\"\"\n",
        "    Returns an array of bounding boxes of human faces in a image\n",
        "\n",
        "    :param img: An image (as a numpy array)\n",
        "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
        "    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n",
        "                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n",
        "    :return: A list of dlib 'rect' objects of found face locations\n",
        "    \"\"\"\n",
        "    if model == \"cnn\":\n",
        "        return cnn_face_detector(img, number_of_times_to_upsample)\n",
        "    else:\n",
        "        return face_detector(img, number_of_times_to_upsample)\n",
        "\n",
        "\n",
        "def face_locations(img, number_of_times_to_upsample=1, model=\"hog\"):\n",
        "    \"\"\"\n",
        "    Returns an array of bounding boxes of human faces in a image\n",
        "\n",
        "    :param img: An image (as a numpy array)\n",
        "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
        "    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n",
        "                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n",
        "    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n",
        "    \"\"\"\n",
        "    if model == \"cnn\":\n",
        "        return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, \"cnn\")]\n",
        "    else:\n",
        "        return [_trim_css_to_bounds(_rect_to_css(face), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, model)]\n",
        "\n",
        "\n",
        "def _raw_face_locations_batched(images, number_of_times_to_upsample=1, batch_size=128):\n",
        "    \"\"\"\n",
        "    Returns an 2d array of dlib rects of human faces in a image using the cnn face detector\n",
        "\n",
        "    :param images: A list of images (each as a numpy array)\n",
        "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
        "    :return: A list of dlib 'rect' objects of found face locations\n",
        "    \"\"\"\n",
        "    return cnn_face_detector(images, number_of_times_to_upsample, batch_size=batch_size)\n",
        "\n",
        "\n",
        "def batch_face_locations(images, number_of_times_to_upsample=1, batch_size=128):\n",
        "    \"\"\"\n",
        "    Returns an 2d array of bounding boxes of human faces in a image using the cnn face detector\n",
        "    If you are using a GPU, this can give you much faster results since the GPU\n",
        "    can process batches of images at once. If you aren't using a GPU, you don't need this function.\n",
        "\n",
        "    :param images: A list of images (each as a numpy array)\n",
        "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
        "    :param batch_size: How many images to include in each GPU processing batch.\n",
        "    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n",
        "    \"\"\"\n",
        "    def convert_cnn_detections_to_css(detections):\n",
        "        return [_trim_css_to_bounds(_rect_to_css(face.rect), images[0].shape) for face in detections]\n",
        "\n",
        "    raw_detections_batched = _raw_face_locations_batched(images, number_of_times_to_upsample, batch_size)\n",
        "\n",
        "    return list(map(convert_cnn_detections_to_css, raw_detections_batched))\n",
        "\n",
        "\n",
        "def _raw_face_landmarks(face_image, face_locations=None, model=\"large\"):\n",
        "    if face_locations is None:\n",
        "        face_locations = _raw_face_locations(face_image)\n",
        "    else:\n",
        "        face_locations = [_css_to_rect(face_location) for face_location in face_locations]\n",
        "\n",
        "    pose_predictor = pose_predictor_68_point\n",
        "\n",
        "    if model == \"small\":\n",
        "        pose_predictor = pose_predictor_5_point\n",
        "\n",
        "    return [pose_predictor(face_image, face_location) for face_location in face_locations]\n",
        "\n",
        "\n",
        "def face_landmarks(face_image, face_locations=None, model=\"large\"):\n",
        "    \"\"\"\n",
        "    Given an image, returns a dict of face feature locations (eyes, nose, etc) for each face in the image\n",
        "\n",
        "    :param face_image: image to search\n",
        "    :param face_locations: Optionally provide a list of face locations to check.\n",
        "    :param model: Optional - which model to use. \"large\" (default) or \"small\" which only returns 5 points but is faster.\n",
        "    :return: A list of dicts of face feature locations (eyes, nose, etc)\n",
        "    \"\"\"\n",
        "    landmarks = _raw_face_landmarks(face_image, face_locations, model)\n",
        "    landmarks_as_tuples = [[(p.x, p.y) for p in landmark.parts()] for landmark in landmarks]\n",
        "\n",
        "    # For a definition of each point index, see https://cdn-images-1.medium.com/max/1600/1*AbEg31EgkbXSQehuNJBlWg.png\n",
        "    if model == 'large':\n",
        "        return [{\n",
        "            \"chin\": points[0:17],\n",
        "            \"left_eyebrow\": points[17:22],\n",
        "            \"right_eyebrow\": points[22:27],\n",
        "            \"nose_bridge\": points[27:31],\n",
        "            \"nose_tip\": points[31:36],\n",
        "            \"left_eye\": points[36:42],\n",
        "            \"right_eye\": points[42:48],\n",
        "            \"top_lip\": points[48:55] + [points[64]] + [points[63]] + [points[62]] + [points[61]] + [points[60]],\n",
        "            \"bottom_lip\": points[54:60] + [points[48]] + [points[60]] + [points[67]] + [points[66]] + [points[65]] + [points[64]]\n",
        "        } for points in landmarks_as_tuples]\n",
        "    elif model == 'small':\n",
        "        return [{\n",
        "            \"nose_tip\": [points[4]],\n",
        "            \"left_eye\": points[2:4],\n",
        "            \"right_eye\": points[0:2],\n",
        "        } for points in landmarks_as_tuples]\n",
        "    else:\n",
        "        raise ValueError(\"Invalid landmarks model type. Supported models are ['small', 'large'].\")\n",
        "\n",
        "\n",
        "def face_encodings(face_image, known_face_locations=None, num_jitters=1, model=\"small\"):\n",
        "    \"\"\"\n",
        "    Given an image, return the 128-dimension face encoding for each face in the image.\n",
        "\n",
        "    :param face_image: The image that contains one or more faces\n",
        "    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\n",
        "    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\n",
        "    :param model: Optional - which model to use. \"large\" or \"small\" (default) which only returns 5 points but is faster.\n",
        "    :return: A list of 128-dimensional face encodings (one for each face in the image)\n",
        "    \"\"\"\n",
        "    raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model)\n",
        "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]\n",
        "\n",
        "\n",
        "def compare_faces(known_face_encodings, face_encoding_to_check, tolerance=0.6):\n",
        "    \"\"\"\n",
        "    Compare a list of face encodings against a candidate encoding to see if they match.\n",
        "\n",
        "    :param known_face_encodings: A list of known face encodings\n",
        "    :param face_encoding_to_check: A single face encoding to compare against the list\n",
        "    :param tolerance: How much distance between faces to consider it a match. Lower is more strict. 0.6 is typical best performance.\n",
        "    :return: A list of True/False values indicating which known_face_encodings match the face encoding to check\n",
        "    \"\"\"\n",
        "    return list(face_distance(known_face_encodings, face_encoding_to_check) <= tolerance)"
      ],
      "metadata": {
        "id": "NTs72jNUKFqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qag0IadWHurU",
        "outputId": "ccceabac-1fe9-4922-849d-d9a2427684c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566171 sha256=e3a7291d6d5c6c40d3ca53c06aeb50df01b0ee77028ce81319f5f443cd23f755\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install face_recognition\n",
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "%cd MyDrive/FR/\n",
        "%ls unknown/\n",
        "%ls known/\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlzDYvvHNYAx",
        "outputId": "716078d3-0f58-469d-a4c1-f0a4781fcd6b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n",
            "/gdrive/MyDrive/FR\n",
            "Aaron_Peirsol_0003.jpg  Adam_Scott_0002.jpg   Zydrunas_Ilgauskas_0001.jpg\n",
            "Adam_Sandler_0004.jpg   Ben_Affleck_0007.jpg\n",
            "'Aaron Peirsol.jpg'  'Adam Scott.jpg'   'Donald Trump.jpg'\n",
            "'Adam Sandler.jpg'   'Ben Affleck.jpg'  'Mike Pence.jpg'\n"
          ]
        }
      ]
    }
  ]
}